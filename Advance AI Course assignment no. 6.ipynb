{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hope to skill                            \n",
        "## Assignment no. 6:\n",
        "### Artificial neural networks(ANN)  \n",
        "---\n",
        "\n",
        "    \n",
        "\n",
        "**UMER TARIQ**                                                           \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3bGJVzP67kPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Artificial Neural Network](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20230602113310/Neural-Networks-Architecture.png)"
      ],
      "metadata": {
        "id": "UxC8pOWKG543"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Artificial Neural Network(ANN, FCN, MLP, NN, FFNN etc):**  \n",
        "\n",
        "ANN are inspired from human brain. They are the earliest neural network architecture.\n",
        "\n",
        "**Structure:**  \n",
        "Their single unit of conputation is called **neuron**. It contains some **weights** and a **bias** which it learns during the training. One neuron can have more than one weight but has only one bias. Number of weights depend on the input of the neuron. The more parameter the model has the more complex it is and more compute it will take to train. These neurons also conatain a non-linear part, the **activation function**. I can be any one from relu(and its varients), tanh, sigmoid, softmax. This adds non-linearity to the model, making it more complex then a simple linear regression.  \n",
        "We stack many neurons on top of one another to make a **layer of neurons**(usually called dense layer or fully connected layer as each neuron in one layer is attacked to the every neuron in the previous and next layer). These can be classified into **input layer**, **hidden layer** or **output layer**\n",
        "Then we stack these layers one after another to create a sequence of layers. This is how a **sequential model** is formed. The input passes through this stack of layer and transformed into output(it can be a class in case of classification or a number in case of regression or any other output)  \n",
        "This is the simplest architecture we can think of. We can add other type of layer like preprocessing, normalization, dropout layers etc.\n",
        "\n",
        "**Working:**\n",
        "An ANN worked in two step:\n",
        "* Forward proppagation\n",
        "* Backward propagation  \n",
        "\n",
        "**Training:**  \n",
        "1. When we train the model it first does the forward propagation.\n",
        "2. Then calculates the loss\n",
        "3. Then does the backward propagation using the optimizer we defined in the model compilation(Usually gradient descent or its varients). Backward propagation tuned the parameter of the model(weights and biases of each neuron)\n",
        "\n",
        "**Prediction:**   \n",
        "When we make prediction using the model it only does the forward propagation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yss-J49V8oyT"
      }
    }
  ]
}